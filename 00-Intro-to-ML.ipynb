{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Machine Learning?\n",
    "\n",
    "Machine learning discovers patterns within data without being explicitly programmed.  This lesson introduces machine learning, explores the main topics in the field, and builds an end-to-end pipeline in Spark.\n",
    "\n",
    "#### Agenda:\n",
    "* Define machine learning\n",
    "* Differentiate supervised and unsupervised tasks\n",
    "* Identify regression and classification tasks\n",
    "* Feature Engineering\n",
    "* Data Science/Machine Learning Libraries\n",
    "* Data Science Development Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from Data\n",
    "\n",
    "[Machine learning](https://en.wikipedia.org/wiki/Machine_learning) refers to a diverse set of tools for understanding data.  More technically, **machine learning is the process of _learning from data_ without being _explicitly programmed_**.  Let's unpack what that means.\n",
    "\n",
    "<div><img src=\"https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/1567241163051-NHBVCU8VKRDE39PE9UQZ/ke17ZwdGBToddI8pDm48kPGprB_J7muXqFrVv-c4smgUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIDnQgARQonPw1_f0DFweYJpL0lKJQUVzHe7UX4v0bxTsRz2rCT34JXMAKCNI0DxY/JPEG+image.jpeg\" style=\"height: 250px; margin: 20px\"/>\n",
    "  \n",
    "Take the Titanic dataset for example.  The dataset consists of the passanger details, such as sex, age, and cabin class, along with their survival status.  Here, the survival value is the _output variable_, also known as the _label_.  The other variables are known as _input variables_ or _features_.\n",
    "\n",
    "**Machine learning is the set of approaches for estimating this function `f()` that maps features to an output.**  The inputs to this function can range from stock prices and customer information to images and DNA sequences.  Many of the same statistical techniques apply regardless of the domain.  This makes machine learning a generalizable skill set that drives decision-making in modern businesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised vs Unsupervised Learning\n",
    "\n",
    "Machine learning problems are roughly categorized into two main types:<br><br>\n",
    "\n",
    "* **Supervised learning** looks to predict the value of some outcome based on one or more input measures\n",
    "  - Our example of the Titanic Dataset is an example of supervised learning\n",
    "  - In this case, the output is the survival status and the input is passanger features, such as age and cabin class\n",
    "* **Unsupervised learning** describes associations and patterns in data without a known outcome\n",
    "  - An example of this would be clustering customer data to find the naturally occurring customer segments\n",
    "  - In this case, no known output is used as an input.  Instead, the goal is to discover how the data are organized into natural segments or clusters\n",
    "\n",
    "This course will cover supervised learning, which is the vast majority of machine learning use cases in industry.  Later courses will look at unsupervised approaches.\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/regression.png\" style=\"height: 400px; margin: 20px\"/><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/clustering.png\" style=\"height: 400px; margin: 20px\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression vs Classification\n",
    "\n",
    "Variables can either be quantitative or qualitative:<br><br>\n",
    "\n",
    "* **Quantitative** values are numeric and generally unbounded, taking any positive or negative value\n",
    "* **Qualitative** values take on a set number of classes or categories\n",
    "\n",
    "| Variable type    | Also known as         | Examples                                                          |\n",
    "|:-----------------|:----------------------|:------------------------------------------------------------------|\n",
    "| quantitative     | continuous, numerical | age, salary, temperature                                          |\n",
    "| qualitative      | categorical, discrete | gender, whether or a not a patient has cancer, state of residence |\n",
    "\n",
    "Machine learning models operate on numbers so a qualitative variable like gender, for instance, would need to be encoded as `0` for male or `1` for female.  In this case, female isn't \"one more\" than male, so this variable is handled differently compared to a quantitative variable.\n",
    "\n",
    "Generally speaking, **a supervised model learning a quantitative variable is called regression and a model learning a qualitative variable is called classification.**\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/classification_v_regression.jpg\" style=\"height: 400px; margin: 20px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "**What is a feature?**\n",
    "\n",
    "A feature is an attribute or property shared by all of the independent units on which analysis or prediction is to be done. Any attribute could be a feature, as long as it is useful to the model.  \n",
    "The purpose of a feature, other than being an attribute, would be much easier to understand in the context of a problem. A feature is a characteristic that might help when solving the problem.\n",
    "\n",
    "**What is feature engineering?**  \n",
    "\n",
    "Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning, and is both difficult and expensive. The need for manual feature engineering can be obviated by automated feature learning.\n",
    "\n",
    "The features in your data are important to the predictive models you use and will influence the results you are going to achieve. The quality and quantity of the features will have great influence on whether the model is good or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commonly used terms:\n",
    "\n",
    "** Feature: **<BR>\n",
    "&emsp;An attribute useful for your modeling task\n",
    "  \n",
    "** Feature Importance: **<BR>\n",
    "&emsp;An estimate of the usefulness of a feature\n",
    "\n",
    "** Feature Extraction: **<BR>\n",
    "&emsp;The automatic construction of new features from raw data\n",
    "\n",
    "** Feature Selection: **<BR>\n",
    "&emsp;From many features to a few that are useful\n",
    "  \n",
    "** Feature Construction: **<BR>\n",
    "&emsp;The manual construction of new features from raw data\n",
    "  \n",
    "** Feature Learning: **<BR>\n",
    "&emsp;The automatic identification and use of features in raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Data Science/ML Libraries\n",
    "**At a high level, Data Science/ML libraries provide tools such as:**\n",
    "* ML Algorithms: common learning algorithms such as classification, regression, clustering, and collaborative filtering\n",
    "* Featurization: feature extraction, transformation, dimensionality reduction, and selection\n",
    "* Pipelines: tools for constructing, evaluating, and tuning ML Pipelines\n",
    "* Persistence: saving and load algorithms, models, and Pipelines\n",
    "* Utilities: linear algebra, statistics, data handling, etc.\n",
    "\n",
    "### Some Libraries are:\n",
    "\n",
    "* Numpy, Pandas (Computation)\n",
    "* Matplotlib (Data Viz.)\n",
    "* Scikit-learn (ML)\n",
    "* PySpark, MLlib (BigData, ML, Pipelining)\n",
    "* TensorFlow (DL)\n",
    "* PyTorch (DL)\n",
    "\n",
    "\n",
    "See [MLlib Guide](https://spark.apache.org/docs/latest/ml-guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science Development Cycle\n",
    "\n",
    "Data scientists follow an iterative workflow that keeps their work closely aligned to both business problems and their data.  This cycle begins with a thorough understanding of the business problem and the data itself, a process called _exploratory data analysis_.  Once the motivating business question and data are understood, the next step is preparing the data for modeling.  This includes removing or imputing missing values and outliers as well as creating features to train the model on.  The majority of a data scientist's work is spent in these earlier steps.\n",
    "\n",
    "After preparing the features in a way that the model can benefit from, the modeling stage uses those features to determine the best way to represent the data.  The various models are then evaluated and this whole process is repeated until the best solution is developed and deployed into production.\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/CRISP-DM.png\" style=\"height: 400px; margin: 20px\"/></div>\n",
    "\n",
    "The above model addresses the high-level development cycle of data products.  This lesson addresses how to implement this at more practical level.\n",
    "\n",
    "<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> <a href=\"https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining\" target=\"_blank\">See the Cross-Industry Standard Process for Data Mining</a> for details on the method above.\n",
    "\n",
    "\n",
    "### Data Science Workflow\n",
    "\n",
    "There is no template for solving a data science problem. The roadmap changes with every new dataset and new problem. But we do see similar steps in many different projects. I wanted to make a clean workflow to serve as an example to aspiring data scientists. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2000/1*3FQbrDoP1w1oibNPj9YeDw.png\"> \n",
    "\n",
    "### Overview:\n",
    "\n",
    "- Source the Data \n",
    "- Data Processing\n",
    "- Modeling\n",
    "- Model Deployment\n",
    "- Model Monitoring \n",
    "- Exploration and reporting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split\n",
    "\n",
    "To implement the development cycle detailed above, data scientists first divide their data randomly into two subsets.  This allows for the evaluation of the model on unseen data.<br><br>\n",
    "\n",
    "1. The **training set** is used to train the model on\n",
    "2. The **test set** is used to test how well the model performs on unseen data\n",
    "\n",
    "This split avoids the memorization of data, known as **overfitting**.  Overfitting occurs when our model learns patterns caused by random chance rather than true signal.  By evaluating our model's performance on unseen data, we can minimize overfitting.\n",
    "\n",
    "Splitting training and test data should be done so that the amount of data in the test set is a good sample of the overall data.  **A split of 80% of your data in the training set and 20% in the test set is a good place to start.**\n",
    "\n",
    "<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-1/train-test-split.png\" style=\"height: 400px; margin: 20px\"/></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
